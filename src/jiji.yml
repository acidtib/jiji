# Project name (required)
# All audit logs, deployment locks, directories and files will be stored under .jiji/{project}/ on remote hosts
project: myproject

# Builder Configuration
# ====================
# Controls how container images are built and where they're stored
# Supports both local builds (on your machine) and remote builds (on dedicated build servers)
#
# Note: Build-specific options like context, dockerfile, and args are configured per-service
# in the services section under the 'build' option. The builder section contains global
# settings that apply to all builds.

builder:
  # Container engine for building
  # Options: docker, podman
  engine: podman

  # Build location - determines where images are built
  local: true

  # Remote builder SSH connection (required when local: false)
  # Enables building on remote servers with more resources or different architectures
  # Format: ssh://[user@]hostname[:port]
  # Examples:
  # remote: ssh://builder@192.168.1.50:22
  # remote: ssh://root@build-server.example.com
  # remote: ssh://ubuntu@build-arm64.local:2222

  # Enable build cache (default: true)
  # Set to false to force clean builds everytime (useful for CI/CD or debugging)
  cache: true

  # Container Registry Configuration
  # ===============================
  # Determines where built images are stored and retrieved from
  registry:
    # Registry type: "local" or "remote"
    type: local

    # Local Registry Settings (type: local)
    # Creates a local registry with SSH port forwarding to deployment hosts
    port: 9270

    # Remote Registry Settings (type: remote)
    # Supported: Docker Hub, GitHub Container Registry
    # server: registry.example.com:5000
    # server: ghcr.io
    # server: docker.io
    # username: myuser
    # password: REGISTRY_PASSWORD

# Builder Configuration Examples:
# ===============================
#
# Example 1: Local Development Setup
# builder:
#   engine: podman
#   local: true
#   cache: true
#   registry:
#     type: local
#     port: 9270
#
# Example 2: Remote Building with Local Registry
# builder:
#   engine: docker
#   local: false
#   remote: ssh://builder@192.168.1.100:22
#   cache: true
#   registry:
#     type: local
#     port: 9270
#
# Example 3: Remote Registry (Docker Hub)
# builder:
#   engine: docker
#   local: true
#   cache: false  # Always fresh builds
#   registry:
#     type: remote
#     server: docker.io
#     username: myusername
#     password: DOCKER_HUB_TOKEN
#
# Example 4: AWS ECR Registry
# builder:
#   engine: docker
#   local: true
#   registry:
#     type: remote
#     server: 123456789012.dkr.ecr.us-west-2.amazonaws.com
#     username: AWS
#     password: ECR_TOKEN
#
# Example 5: Remote Building with Custom Registry Port
# builder:
#   engine: podman
#   local: false
#   remote: ssh://build-server@192.168.1.200:22
#   cache: true
#   registry:
#     type: local
#     port: 6000

# Server Definitions (required)
# ===============================
# Define all servers once by name, then reference them in services under hosts:
# This eliminates duplication and allows per-server SSH configuration overrides
#
# Each server must have:
# - Unique name (DNS-safe: alphanumeric + hyphens, no start/end hyphen, max 63 chars)
# - Unique hostname/IP address (no duplicate hosts across servers)
#
# Per-server SSH overrides (all optional, inherit from global ssh section if not specified):
# - user: SSH username for this specific server
# - port: SSH port for this specific server
# - key_path: Path to SSH private key for this server
# - key_passphrase: SSH key passphrase for this server
# - keys: Array of SSH key paths for this server
# - key_data: Array of inline SSH key data from environment variables
#
# Architecture (arch):
# - amd64 (default): x86_64/AMD64 architecture
# - arm64: ARM64/aarch64 architecture
# - Used for multi-architecture image builds

servers:
  # VPS
  vps-prod:
    host: 15.204.224.81
    arch: amd64 # Optional, defaults to amd64

  # Home server with custom SSH user
  home-server:
    host: 192.168.1.220
    arch: amd64
    user: ubuntu # Override global SSH user for this server

  # ARM build server with custom port and key
  arm-builder:
    host: 192.168.1.230
    arch: arm64
    port: 2222 # Custom SSH port
    key_path: ~/.ssh/arm_builder_key # Server-specific SSH key

# Server Configuration Examples:
# ===============================
#
# Example 1: Simple Multi-Server Setup
# servers:
#   server1:
#     host: 192.168.1.100
#   server2:
#     host: 192.168.1.101
#
# Example 2: Mixed Architectures
# servers:
#   amd-server:
#     host: 10.0.0.10
#     arch: amd64
#   arm-server:
#     host: 10.0.0.20
#     arch: arm64
#
# Example 3: Different SSH Users Per Server
# servers:
#   ubuntu-box:
#     host: 192.168.1.10
#     user: ubuntu
#   centos-box:
#     host: 192.168.1.20
#     user: centos

# SSH configuration for remote connections
ssh:
  user: root
  port: 22
  # Optional: Path to SSH private key
  # key_path: ~/.ssh/id_rsa
  # Optional: SSH key passphrase
  # key_passphrase: "your-passphrase"
  # Optional: Connection timeout in seconds (default: 30)
  # connect_timeout: 30
  # Optional: Command timeout in seconds (default: 300)
  # command_timeout: 300
  # Optional: Additional SSH options
  # options:
  #   StrictHostKeyChecking: "no"
  #   UserKnownHostsFile: "/dev/null"

  # Log Level Configuration
  # Controls verbosity of SSH operation logging
  # Options: debug, info, warn, error, fatal (default: error)
  # - debug: Show all SSH operations and detailed connection info
  # - info: Show major operations and status updates
  # - warn: Show warnings and important notices
  # - error: Show only errors and failures (default)
  # - fatal: Show only critical failures
  # log_level: error

  # Multiple Private Keys Support
  # Specify multiple key files (paths are expanded automatically, ~ supported)
  # keys:
  #   - ~/.ssh/id_rsa
  #   - ~/.ssh/deploy_key
  #   - /path/to/special_key

  # Inline Key Data from Environment Variables
  # Useful for CI/CD where keys are stored as secrets
  # key_data:
  #   - SSH_PRIVATE_KEY_1
  #   - SSH_PRIVATE_KEY_2

  # Keys Only Mode - ignore ssh-agent, use only specified keys
  # Set to true to disable ssh-agent and use only keys specified above
  # keys_only: false

  # Concurrency Control
  # Limit concurrent SSH connections to prevent overwhelming servers
  # max_concurrent_starts: 30

  # Connection pool idle timeout in seconds
  # pool_idle_timeout: 900

  # DNS lookup retry attempts (with exponential backoff)
  # dns_retries: 3

  # SSH Proxy/Jump Host Configuration
  # Use either 'proxy' (ProxyJump) or 'proxy_command' (ProxyCommand), not both

  # ProxyJump - Simple bastion/jump host
  # Automatically tunnels SSH connections through the specified proxy host
  # Format: [user@]hostname[:port]
  # Examples:
  # proxy: root@bastion.example.com
  # proxy: bastion.example.com:2222
  # proxy: deploy@jump-host

  # ProxyCommand - Custom proxy command with full control
  # Executes a custom command to establish the SSH connection
  # Use %h for target hostname and %p for target port
  # Examples:
  # proxy_command: "ssh -W %h:%p user@proxy.example.com"
  # proxy_command: "ssh -W %h:%p -i ~/.ssh/bastion_key bastion.example.com"
  # proxy_command: "nc -X connect -x proxy.example.com:3128 %h %p"

  # SSH Configuration File Support
  # Load SSH configuration from ~/.ssh/config files to leverage existing SSH setups
  # This allows Jiji to inherit host-specific settings like ProxyJump, IdentityFile, etc.
  # Jiji configuration takes precedence over SSH config file settings

  # Load SSH config files:
  # config: true                    # Load default files (~/.ssh/config, /etc/ssh/ssh_config)
  # config: "~/.ssh/custom_config"  # Load specific file
  # config:                         # Load multiple files
  #   - ~/.ssh/config
  #   - ~/.ssh/work_config
  # config: false                   # Don't load config files (default)

  # When enabled, Jiji will:
  # - Parse SSH config files for host-specific settings
  # - Apply matching Host patterns (supports wildcards * and ?)
  # - Use ProxyJump/ProxyCommand from config if not set in Jiji
  # - Use IdentityFile from config if no keys specified in Jiji
  # - Apply connection timeouts and other SSH options
  # - Always prioritize Jiji configuration over SSH config file settings

# Private Networking Configuration
# ================================
# Enables secure, encrypted container-to-container communication across servers
# using WireGuard VPN mesh network with automatic service discovery via DNS
#
# Network Architecture:
# - WireGuard: Creates encrypted mesh VPN between all servers
# - Corrosion: Distributed CRDT database for service registry (gossip protocol)
# - jiji-dns: DNS server for service discovery (resolves <project>-<service>.jiji to container IPs)
# - Dual-stack: IPv4 (10.210.0.0/16) for containers, IPv6 (fdcc::/16) for management
# - Automatic: Containers are auto-registered on deploy, auto-unregistered on remove
#
# Use Cases:
# - Microservices communication without exposing ports publicly
# - Multi-server deployments with service discovery
# - Database replication across servers
# - Secure inter-service authentication
# - Zero-trust networking with encryption by default
#
# network:
#   # Enable private networking (default: true)
#   enabled: true
#
#   # Cluster CIDR for container networking
#   # Each server gets a /24 subnet (254 usable IPs per server)
#   # Default: 10.210.0.0/16 (supports 256 servers)
#   cluster_cidr: "10.210.0.0/16"
#
#   # Note: Service domain is always 'jiji' - containers reach each other via <project>-<service>.jiji
#   # Note: Service discovery method is always 'corrosion' (distributed CRDT-based)
#   # Note: Corrosion gossip port (9280) and API port (9220) are not configurable
#
# Network Configuration Examples:
# ==============================
#
# Example 1: Basic Setup (Recommended)
# network:
#   enabled: true
#   cluster_cidr: "10.210.0.0/16"
#
# Example 2: Custom CIDR for Existing Network
# network:
#   enabled: true
#   cluster_cidr: "172.20.0.0/16"    # Avoid conflicts with existing networks
#
# Example 3: Disable Networking
# network:
#   enabled: false
#
# Service Communication Example:
# ============================
# Given this configuration:
#
# servers:
#   server1:
#     host: 192.168.1.100
#   server2:
#     host: 192.168.1.101
#   server3:
#     host: 192.168.1.102
#
# services:
#   api-backend:
#     hosts:
#       - server1
#       - server2
#
#   database:
#     hosts:
#       - server3
#
# The api-backend containers can connect to database via (assuming project: myapp):
#   DATABASE_URL: postgresql://user:pass@myapp-database.jiji:5432/myapp
#
# And database can connect back to api via:
#   API_URL: http://myapp-api-backend.jiji:3000

# Secrets Configuration
# ====================
# Secrets are loaded from .env files in your project root.
#
# File Loading Priority:
# 1. .env.{environment} - When using -e/--environment flag (e.g., .env.staging)
# 2. .env - Fallback when no environment specific file exists
#
# Optional: Custom path to .env file (relative to project root)
# secrets_path: .secrets  # Will load .secrets.{environment} or .secrets
#
# Host Environment Fallback:
# By default, jiji ONLY reads from .env files. Use --host-env flag to allow
# fallback to host environment variables when secrets are not found in .env files.
#
# Example: jiji -e production --host-env deploy
#
# Debug Secrets:
# Use 'jiji secrets print' to see which secrets are configured and their status.
# Use 'jiji secrets print --show-values' to reveal actual secret values (use with caution).
#
# Error Handling:
# If secrets are defined but cannot be resolved (not in .env or host env),
# the command will fail with an error listing the missing secrets.

# Shared Environment Configuration
# Applied to all services, can be overridden per-service
environment:
  # Clear text environment variables
  clear:
    APP_ENV: production
    LOG_LEVEL: info
    DEBUG: "false"
  # Secrets loaded from .env files (or host environment with --host-env)
  # List secret names that must be provided in .env.{environment} or .env file
  secrets:
    - DATABASE_PASSWORD
    - API_SECRET_KEY

# Services Configuration
# Services are the deployable units in Jiji - each service represents a containerized application
# Use service filtering during deployment to target specific services or groups
#
# Service Filtering:
# Target specific services with the --services flag:
#   jiji server init --services web-frontend
#   jiji server init --services web-frontend,api-backend
#   jiji server exec "docker ps" --services web-*
#
# Service filters support wildcards (* pattern matching):
#   --services "web-*"           # Matches: web-frontend, web-api, web-worker
#   --services "api-*,worker-*"  # Multiple wildcard patterns
#
# Combine with host filtering for precise targeting:
#   jiji server exec "systemctl status docker" --services web-* --hosts 192.168.1.100
#
# Image Retention Configuration:
# =============================
# Jiji automatically prunes old Docker/Podman images after deployment to save disk space
# while keeping recent versions for rollbacks. Configure retention per service:
#
# retain: <number>   # Number of recent images to keep (default: 3)
#
# Image Retention Examples:
# - retain: 3        # Keep last 3 images (default)
# - retain: 5        # Keep last 5 images for critical services
# - retain: 1        # Keep only the latest image for non-critical services
#
# Manual Pruning:
# Run 'jiji services prune' to manually clean up images outside of deployment
# Use 'jiji services prune --retain 5' to override the default retention setting
#
services:
  # Example: Web frontend service using pre-built image
  web-frontend:
    image: nginx:latest
    # Server targets: Reference servers by name from the servers section
    hosts:
      - vps-prod
      - home-server
    # Port Mappings: Map host ports to container ports
    # Supported formats:
    #   - "8000"                           # Container port only (host port auto-assigned)
    #   - "8080:8000"                      # host_port:container_port
    #   - "127.0.0.1:8080:80"              # host_ip:host_port:container_port
    #   - "8080:8000/tcp"                  # Specify TCP protocol (default)
    #   - "1900/udp"                       # Container port with UDP protocol
    #   - "53:53/udp"                      # Host:container with UDP
    #   - "127.0.0.1:5353:53/udp"          # Full format with IP and UDP
    # Protocol suffix: /tcp or /udp (optional, defaults to TCP)
    # Port range: 1-65535
    # IP: Valid IPv4 address (bind to specific interface)
    ports:
      - "127.0.0.1:8080:80"
    # Image Retention: Number of images to keep for rollbacks (default: 3)
    # Older images are automatically pruned after deployment
    retain: 5
    # Volumes: Docker/Podman named volumes or host paths
    volumes:
      - "web_storage:/opt/uploads"
      - "./data:/opt/extra_data:ro"
    # Files: Upload from local repo to host .jiji/{project}/files/ before mounting
    # String format: local:remote[:options] where options can be ro, z, or Z
    files:
      - "nginx.conf:/etc/nginx/nginx.conf:ro"
    # Or use hash format for custom permissions and ownership:
    # files:
    #   - local: config/secret.key
    #     remote: /etc/app/secret.key
    #     mode: "0600"
    #     owner: "nginx:nginx"
    #     options: "ro"
    # Directories: Created on host .jiji/{project}/directories/ before mounting
    # String format: local:remote[:options] where options can be ro, z, or Z
    directories:
      - "html:/usr/share/nginx/html:ro"
    # Or use hash format for custom permissions and ownership:
    # directories:
    #   - local: logs
    #     remote: /var/log/nginx
    #     mode: "0755"
    #     owner: "nginx:nginx"
    #     options: "z"
    # Service-specific environment (merged with shared environment)
    environment:
      clear:
        NGINX_WORKER_PROCESSES: auto
        NGINX_WORKER_CONNECTIONS: "1024"
    # Optional: Proxy configuration for automatic SSL and routing
    # Single Target Proxy Configuration
    # proxy:
    #   app_port: 80                           # Required: container port to proxy
    #   ssl: false                             # Option A: no TLS
    #   # ssl: true                            # Option B: Let's Encrypt auto-provisioning
    #   # ssl:                                 # Option C: Custom certificates from secrets
    #   #   certificate_pem: CERTIFICATE_PEM  #   env var name containing the certificate PEM
    #   #   private_key_pem: PRIVATE_KEY_PEM  #   env var name containing the private key PEM
    #   host: web.myproject.example.com        # Single host domain
    #   # Or use hosts (plural) for multiple domains pointing to the same target:
    #   # hosts:
    #   #   - web.myproject.example.com
    #   #   - www.myproject.example.com
    #   #   - myproject.example.com
    #   path_prefix: /api                      # Optional: Path-based routing
    #   healthcheck:
    #     path: /health              # HTTP health check endpoint
    #     interval: 10s

  # Example: API service using custom build with single-target proxy
  # api-backend:
  #   build:
  #     context: ./api                    # Build context (relative to project root)
  #     dockerfile: Dockerfile           # Dockerfile path (relative to context)
  #     target: production               # Build target for multi-stage Dockerfiles
  #     args:                            # Build arguments for this service
  #       NODE_ENV: production
  #       API_VERSION: "2.1.0"
  #       BUILD_DATE: BUILD_DATE
  #   hosts:                              # Deploy to both amd64 and arm64 servers
  #     - vps-prod
  #     - arm-builder
  #   ports:
  #     - "3000:3000"
  #   environment:
  #     clear:
  #       NODE_ENV: production
  #       DATABASE_URL: "postgresql://user:pass@192.168.1.103:5432/myapp"
  #       REDIS_URL: "redis://redis.local:6379"
  #     secrets:
  #       - JWT_SECRET
  #       - API_KEY
  #   command: ["node", "dist/server.js"]
  #   volumes:
  #     - "/app/logs:/var/log/app"
  #   # Single Target Proxy - Host-based routing (separate subdomain)
  #   proxy:
  #     app_port: 3000                    # Required: container port
  #     ssl: true
  #     host: api.myproject.example.com
  #     healthcheck:
  #       path: /api/health               # HTTP health check endpoint
  #       interval: 15s
  #       timeout: 10s
  #       deploy_timeout: 60s
  #   # Or with command-based health check (for containers without HTTP endpoints)
  #   # proxy:
  #   #   app_port: 3000
  #   #   ssl: true
  #   #   host: api.myproject.example.com
  #   #   healthcheck:
  #   #     cmd: "test -f /app/ready"     # Command health check (exit code 0 = healthy)
  #   #     cmd_runtime: docker           # Optional: Runtime (docker/podman, defaults to builder.engine)
  #   #     interval: 15s
  #   #     timeout: 10s
  #   #     deploy_timeout: 60s
  #   # Or path-based routing (same domain, different path)
  #   # proxy:
  #   #   app_port: 3000
  #   #   ssl: true
  #   #   host: myproject.example.com
  #   #   path_prefix: /api
  #   #   healthcheck:
  #   #     path: /api/health
  #   #     interval: 15s
  #   #     timeout: 10s
  #   #     deploy_timeout: 60s
  #   # Or combined routing (specific host + path prefix)
  #   # proxy:
  #   #   app_port: 3000
  #   #   ssl: true
  #   #   host: app.myproject.example.com
  #   #   path_prefix: /v2
  #   #   healthcheck:
  #   #     path: /v2/health
  #   #     interval: 15s
  #   #     timeout: 10s
  #   #     deploy_timeout: 60s

  # Example: Multi-Target Proxy for services with multiple ports
  # Useful for services like Garage that expose multiple APIs
  # garage:
  #   image: dxflrs/garage:v2.1.0
  #   hosts:
  #     - storage-server
  #   ports:
  #     - "127.0.0.1:3900:3900"           # S3 API
  #     - "127.0.0.1:3903:3903"           # Admin API
  #   volumes:
  #     - "garage_meta:/var/lib/garage/meta"
  #     - "garage_data:/var/lib/garage/data"
  #   files:
  #     - "garage.toml:/etc/garage.toml"
  #   # Multi-Target Proxy Configuration
  #   proxy:
  #     targets:
  #       - app_port: 3900                # S3 API endpoint
  #         host: s3.garage.example.com
  #         ssl: false
  #         healthcheck:
  #           path: /health               # HTTP health check endpoint
  #           interval: 30s
  #           deploy_timeout: 60s
  #       - app_port: 3903                # Admin API endpoint
  #         host: admin.garage.example.com
  #         ssl: true
  #         healthcheck:
  #           path: /health               # HTTP health check endpoint
  #           interval: 30s
  #           deploy_timeout: 60s
  #   # Note: Each target is deployed as {project}-{service}-{app_port} in kamal-proxy
  #   # Example: myproject-garage-3900, myproject-garage-3903
  #
  # Health Check Configuration:
  # ==========================
  # Jiji supports two types of health checks via kamal-proxy:
  #
  # 1. HTTP Health Checks (default)
  #    - Uses HTTP GET requests to check container health
  #    - Best for web services with HTTP endpoints
  #    - Example:
  #      healthcheck:
  #        path: /health                  # HTTP endpoint to check (e.g., "/health", "/up")
  #        interval: 10s                  # Check interval (default: 10s)
  #        timeout: 5s                    # Request timeout (default: 5s)
  #        deploy_timeout: 60s            # Max wait for initial deployment (default: 60s)
  #
  # 2. Command-based Health Checks
  #    - Executes commands via docker exec or podman exec
  #    - Exit code 0 = healthy, any other exit code = unhealthy
  #    - Best for non-HTTP services or custom health logic
  #    - Compatible with distroless/scratch containers
  #    - Example:
  #      healthcheck:
  #        cmd: "test -f /app/ready"      # Command to execute (exit 0 = healthy)
  #        cmd_runtime: docker            # Optional: Runtime (docker/podman, auto-detects from builder.engine)
  #        interval: 10s                  # Check interval (default: 10s)
  #        timeout: 5s                    # Command timeout (default: 5s)
  #        deploy_timeout: 60s            # Max wait for initial deployment (default: 60s)
  #
  # Command Health Check Examples:
  # - File-based readiness: cmd: "test -f /app/ready"
  # - Process check: cmd: "pgrep -f myapp"
  # - Custom script: cmd: "/app/healthcheck.sh"
  # - Internal HTTP check: cmd: "curl -f http://localhost:3000/health"
  # - Complex check: cmd: '/app/healthcheck --config "/etc/app.conf"'
  #
  # Notes:
  # - HTTP (path) and command (cmd) health checks are mutually exclusive
  # - Health checks are used for both initial deployment and ongoing monitoring
  # - Failed health checks during deployment keep old containers running (zero-downtime)

  # Admin service with path-based routing
  # admin-panel:
  #   build:
  #     context: ./admin
  #     dockerfile: Dockerfile
  #   hosts:
  #     - web-server
  #   ports:
  #     - "3000"
  #   environment:
  #     clear:
  #       NODE_ENV: production
  #   proxy:
  #     ssl: true
  #     host: myproject.example.com
  #     path_prefix: /admin

# Server Architecture Configuration Examples:
#
# 1. Single architecture deployment (in top-level servers section):
#   servers:
#     server1:
#       host: 192.168.1.100
#       arch: amd64
#     server2:
#       host: 192.168.1.101
#       arch: amd64
#
# 2. Mixed architecture deployment:
#   servers:
#     amd-server:
#       host: 192.168.1.100
#       arch: amd64
#     arm-server:
#       host: 192.168.1.101
#       arch: arm64
#
# 3. ARM-only deployment:
#   servers:
#     arm1:
#       host: 192.168.1.200
#       arch: arm64
#     arm2:
#       host: 192.168.1.201
#       arch: arm64
#
# Notes:
# - Servers are defined at root level, services reference them under hosts:
# - Supported architectures: amd64, arm64
# - If no arch specified, defaults to amd64
# - Jiji automatically builds multi-architecture images when needed

# GraphQL API with path-based routing
# graphql-api:
#   build:
#     context: ./graphql
#     dockerfile: Dockerfile
#   hosts:
#     - api-server
#   ports:
#     - "4000:4000"
#   environment:
#     clear:
#       NODE_ENV: production
#   proxy:
#     ssl: true
#     host: myproject.example.com
#     path_prefix: /graphql
#     healthcheck:
#       path: /graphql/health
#       interval: 15s

# Example: Worker service for background jobs
# worker-queue:
#   build:
#     context: ./worker
#     dockerfile: Dockerfile
#   hosts:
#     - worker-server
#   environment:
#     clear:
#       QUEUE_URL: "redis://192.168.1.104:6379"
#       WORKER_CONCURRENCY: "4"
#   command: ["npm", "run", "worker"]
#   volumes:
#     - "/app/worker-data:/data"

# Example: Database service
# database:
#   image: postgres:15-alpine
#   hosts:
#     - db-server
#   ports:
#     - "127.0.0.1:5432:5432"
#   environment:
#     clear:
#       POSTGRES_DB: myapp
#       POSTGRES_USER: appuser
#       POSTGRES_PASSWORD: securepassword
#   volumes:
#     - "/data/postgres:/var/lib/postgresql/data"

# Example: Cache service
# cache:
#   image: redis:7-alpine
#   hosts:
#     - cache-server
#   ports:
#     - "127.0.0.1:6379:6379"
#   volumes:
#     - "/data/redis:/data"
#   command: ["redis-server", "--appendonly", "yes"]
#
# # Example: DNS server with UDP ports
# dns-server:
#   image: coredns/coredns:latest
#   hosts:
#     - dns-server
#   ports:
#     - "53:53/udp"              # DNS queries over UDP
#     - "53:53/tcp"              # DNS zone transfers over TCP
#   volumes:
#     - "./coredns/Corefile:/etc/coredns/Corefile:ro"
#   command: ["-conf", "/etc/coredns/Corefile"]
#
# # Example: Service with mixed TCP/UDP ports
# game-server:
#   image: game-server:latest
#   hosts:
#     - game-server
#   ports:
#     - "8080:8080/tcp"          # HTTP API
#     - "7777:7777/udp"          # Game protocol
#     - "7778:7778/udp"          # Voice chat
#     - "127.0.0.1:9000:9000"    # Admin interface (localhost only)
#
# # Example: ML service with GPU and resource constraints
# ml-trainer:
#   image: tensorflow/tensorflow:latest-gpu
#   hosts:
#     - gpu-server
#   ports:
#     - "8888:8888"              # Jupyter notebook
#   # Resource Constraints:
#   cpus: 4                      # Limit to 4 CPUs (can be fractional: 0.5, 1.5, etc.)
#   memory: "8g"                 # Memory limit (e.g., "512m", "1g", "2gb", "1024mb")
#   gpus: "all"                  # GPU access: "all", "0", "0,1", "device=0"
#   volumes:
#     - "ml_models:/models"
#     - "ml_data:/data"
#   environment:
#     clear:
#       CUDA_VISIBLE_DEVICES: "0"
#
# # Example: Media server with device access
# media-processor:
#   image: ffmpeg:latest
#   hosts:
#     - media-server
#   ports:
#     - "8080:8080"
#   # Device Mappings: Grant access to host devices
#   devices:
#     - "/dev/video0"            # Simple device mapping
#     - "/dev/video1:/dev/video1:rwm"  # With permissions (r=read, w=write, m=mknod)
#     - "/dev/snd"               # Audio devices
#   cpus: 2
#   memory: "2g"
#   volumes:
#     - "media_input:/input"
#     - "media_output:/output"
#
# # Example: FUSE filesystem with privileged mode
# rclone-mount:
#   image: rclone/rclone:latest
#   hosts:
#     - storage-server
#   ports:
#     - "5572:5572"              # WebUI
#   # Privileged mode: Grants extended privileges to container
#   privileged: true             # Required for FUSE mounts
#   devices:
#     - "/dev/fuse"              # FUSE device access
#   memory: "2g"
#   volumes:
#     - "rclone_config:/config"
#     - "rclone_cache:/cache"
#   command: ["rcd", "--rc-web-gui", "--rc-addr", ":5572"]
#
# # Example: Network service with specific capabilities
# vpn-server:
#   image: linuxserver/wireguard:latest
#   hosts:
#     - vpn-server
#   ports:
#     - "51820:51820/udp"        # WireGuard
#   # Linux Capabilities: Add specific capabilities instead of full privileged mode
#   cap_add:
#     - NET_ADMIN                # Network administration operations
#     - SYS_MODULE               # Load/unload kernel modules
#   devices:
#     - "/dev/net/tun"           # TUN device for VPN
#   environment:
#     clear:
#       PEERX_PUBLIC_KEY: "your-public-key"
#       SERVERURL: "vpn.example.com"
#
# Resource Constraints Reference:
# ==============================
#
# cpus: Number of CPUs to allocate
#   - Type: number or string
#   - Examples: 0.5, 1, 2, 4, "1.5"
#   - Limits CPU usage for the container
#
# memory: Memory limit for the container
#   - Type: string with format: number + unit
#   - Units: b, k, m, g, kb, mb, gb (case-insensitive)
#   - Examples: "512m", "1g", "2gb", "1024mb"
#   - Prevents container from using more than specified memory
#
# gpus: GPU device access
#   - Type: string
#   - Examples:
#     - "all" - Access to all available GPUs
#     - "0" - Access to GPU device 0
#     - "0,1" - Access to GPU devices 0 and 1
#     - "device=0" - Specific device notation
#   - Note: Requires NVIDIA Container Toolkit (Docker) or equivalent (Podman)
#
# network_mode: Container network mode
#   - Type: string
#   - Default: "bridge"
#   - Examples: "bridge", "host", "none", "container:<name|id>"
#   - Options:
#     - "bridge" - Default Docker/Podman bridge network (isolated)
#     - "host" - Use host's network stack directly (no isolation)
#     - "none" - No networking
#     - "container:<name>" - Share network namespace with another container
#   - Use Cases:
#     - "host" for services needing low-latency or full network access
#     - "none" for security-sensitive containers with no network needs
#
# devices: Device mappings for hardware access
#   - Type: array of strings
#   - Formats:
#     - "/dev/video0" - Simple mapping (host:container same path)
#     - "/dev/video0:/dev/video0" - Explicit host:container mapping
#     - "/dev/video0:/dev/video0:rwm" - With permissions
#   - Permissions (optional): r (read), w (write), m (mknod)
#   - Common devices:
#     - Video: /dev/video0, /dev/video1
#     - Audio: /dev/snd
#     - GPU: /dev/nvidia0, /dev/nvidiactl
#     - USB: /dev/bus/usb
#     - FUSE: /dev/fuse
#     - TUN: /dev/net/tun
#
# privileged: Run container in privileged mode
#   - Type: boolean
#   - Default: false
#   - Examples: true, false
#   - Grants extended privileges to the container
#   - Security Warning: Gives container nearly all capabilities of the host
#   - Use Cases:
#     - FUSE filesystems (with /dev/fuse device)
#     - Docker-in-Docker
#     - Low-level system operations
#   - Alternative: Use cap_add for specific capabilities when possible
#
# cap_add: Add Linux capabilities to container
#   - Type: array of strings
#   - Default: [] (empty)
#   - Examples: ["SYS_ADMIN"], ["NET_ADMIN", "SYS_MODULE"]
#   - Grants specific Linux capabilities without full privileged mode
#   - More secure than privileged mode - principle of least privilege
#   - Common capabilities:
#     - SYS_ADMIN: Mount filesystems, FUSE operations, namespace operations
#     - NET_ADMIN: Network configuration, routing, firewall rules
#     - NET_RAW: Use RAW and PACKET sockets
#     - SYS_MODULE: Load/unload kernel modules
#     - SYS_PTRACE: Debug processes, trace system calls
#     - SYS_TIME: Set system clock
#     - MKNOD: Create special files (device nodes)
#   - Full list: man 7 capabilities
#   - Note: Capability names should NOT include "CAP_" prefix
#
# stop_first: Stop old container before starting new one
#   - Type: boolean
#   - Default: false
#   - When false: Zero-downtime deployment (rename old → start new → stop old)
#   - When true: Stop-first deployment (stop old → start new)
#   - Use for stateful services that cannot have two instances running:
#     - Databases with file locks (SQLite, LevelDB, embedded stores)
#     - Services registering unique IDs (volume servers, cluster members)
#     - Services with exclusive resource locks (FUSE mounts, GPU memory)
#   - Trade-off: Causes brief downtime but prevents resource conflicts
#   - Warning: No rollback possible if new container fails to start
#   - Example:
#     services:
#       database:
#         image: postgres:15
#         stop_first: true  # Database can't have two instances with same data dir
#       filer:
#         image: seaweedfs/seaweedfs:latest
#         stop_first: true  # LevelDB requires exclusive lock
#

# Proxy Routing Configuration:
# ============================
#
# Jiji supports both host-based and path-based routing:
#
# Host-based routing (different domains/subdomains):
# services:
#   frontend:
#     proxy:
#       ssl: true
#       host: myapp.com
#
#   api:
#     proxy:
#       ssl: true
#       host: api.myapp.com
#
# Path-based routing (same domain, different paths):
# services:
#   frontend:
#     proxy:
#       ssl: true
#       host: myapp.com          # Catch-all
#
#   api:
#     proxy:
#       ssl: true
#       host: myapp.com
#       path_prefix: /api        # Routes myapp.com/api/*
#
#   admin:
#     proxy:
#       ssl: true
#       host: myapp.com
#       path_prefix: /admin      # Routes myapp.com/admin/*
#
# Combined routing (host + path):
# services:
#   api-v1:
#     proxy:
#       ssl: true
#       host: api.myapp.com
#       path_prefix: /v1         # Routes api.myapp.com/v1/*
#
# Routing priority:
# - Longer path prefixes match first (/api/v2 before /api)
# - Services without path_prefix are catch-all for their host

# Service Deployment Filtering Examples:
# =====================================
# Deploy specific services:           jiji deploy -S web-frontend,api-backend
# Deploy by pattern:                  jiji deploy -S "web-*,*-backend"
# Deploy to specific hosts:           jiji deploy -H 192.168.1.100,192.168.1.101
# Build and deploy:                   jiji deploy --build
# Build without cache:                jiji deploy --build --no-cache
# Skip confirmation:                  jiji deploy -y
# Combine filters:                    jiji deploy -S "web-*" -H 192.168.1.100 --build
